\documentclass{proc}
\usepackage{url}
\linespread{1.2}

\begin{document}

\title{Project Proposal: A Container-Based Approach to Fault-Tolerant Host Monitoring on Commodity Operating Systems}

\author{Brett Jia \hspace{1em} Jennifer Bi}

\maketitle

\section*{Abstract}

In modern computer systems, users and developers often desire to monitor their operating systems for usage metrics, such as file system usage, CPU utilization, RAM, and others. Monitoring can be done through automated software that report metrics to a metrics aggregator, or through a user manually running certain tools that probe the operating system for data. In either case, the system could be at risk of damage and compromise from buggy or malicious software and user negligence or error. To address this problem, we present an approach to running host monitoring tools in containers with a read-only view of the surrounding system, guaranteeing fault tolerance and protection to the host operating system.

\section*{1. Introduction}

Despite the best efforts of systems and hardware designers, a major weakness of modern day operating systems is the high level of trust given to user-level application code to allow programs to do what they are designed to do. A word processor is permitted to read and write files to the local filesystem, whereas a web browser is permitted to open sockets and make network connections. Without these capabilities, programs would be rendered useless, much to a computer user's dissatisfaction. Unfortunately, this high level of trust also allows malicious applications, buggy software, and user negligence to cause irreparable damage to the host computer system, resulting in the expenditure of hours and money to restore the system and its contents.

An early solution to the problem of fault tolerance is using a kernel interposition method to restrict an application's access to certain system calls, as implemented in Janus \cite{goldberg1996janus}. Other sandboxing mechanisms have been introduced, including new system calls to create jails \cite{kamp2000jails}
######## TODO
Modern focus has landed on using operating system virtualization through containers. The introduction of containers to the operating system

While many software applications (such as word processors and web browsers) are now distributed through secure channels and feature cryptographic signatures from trusted entities, there are still instances where users want to run untrusted code, but still keep their local system safe from any malicious side effects. For example, web scripting languages such as JavaScript are present in a large majority of websites, which run the untrusted scripts immediately as a webpage loads. As users cannot be expected to disable JavaScript completely (thus rendering most websites unusable), browser designers are forced to design policies and mechanisms to isolate this untrusted code from the rest of the computer. In another case, a security researcher may want to run malware on a local computer for testing and study, but also seek to protect the computer from harm. Additionally, a system administrator may want to open up servers for public use, but limit the operations each user can perform to prevent or limit damage to the overall system.

In each of these situations, the typical solution is to create a sort of restricted environment for unsafe programs to run. Creating such a restricted environment comes in many forms, from using tools and syscalls built into an operating system, to emulating the machine instructions of an application binary, to even using full-featured virtual machines. Selecting a tool from this wide buffet of options can be difficult, and may vary depending on the use case or software to be restricted. In our research, we seek to survey the current state of restricted computing technologies by discussing the different techniques employed, then present a comparison of various programs that provide this restricted computing environment in both objective, hard metrics as well as subjective, soft metrics.

\section*{2. Literature Review}

In preparation for our research, we sought out existing literature on existing application isolation techniques. We discovered a diverse set of techniques used to create isolated and restricted environments for running untrusted code. Our findings are listed below in this section.

A prior survey of isolation systems and techniques from 2009 \cite{viswanathan2009isolation} categorizes isolation techniques into the following categories:
\begin{enumerate}
    \item Language-based isolation (e.g. type safety and compiler verification)
    \item Sandbox-based isolation (e.g. interposition between an application and the operating system's syscalls)
    \item Virtual machine-based isolation (e.g. Type I and Type II hypervisors)
    \item Kernel-based isolation (e.g. isolation between processes)
    \item Hardware-based isolation (e.g. hardware support for virtual memory addresses)
    \item Physical isolation (e.g. airgapped machines)
\end{enumerate}
The taxonomy of isolation techniques and a list of surveyed systems presented in the aforementioned paper provide a useful categorization of restricted computing environment techniques and useful comparisons of the taxonomic categories listed above. For the purposes of our research, we are mainly interested in sandbox-based and virtual machine-based isolation.

Another survey of virtualization technologies for untrusted code execution from 2012 \cite{wen2012virtualization} notes that untrusted code is usually executed in one of four categories:
\begin{enumerate}
    \item Application-level sandboxing through programming language features, kernel interposition, or resource access control policies
    \item Simulating an operating system environment through virtualizing an operating system's runtime API
    \item Containerizing an execution environment through kernel-supported isolation of all resources required by a process
    \item Virtualizing hardware and isolating full operating systems through Type I and Type II virtual machine monitors
\end{enumerate}
This survey by Wen et al. presents various examples of each type of restricted computing environment and discusses their strengths and weaknesses, however fails to present quantitative metrics to compare the technologies listed. Indeed, the research presented by Viswanathan and Neuman \cite{viswanathan2009isolation} also fails to present any sort of benchmarking for the surveyed technologies.

Although these two surveys are useful in providing categorization and terminology, we find them to be dated, as newer forms of restricted computing environments have been developed in recent years. Our own literature review presents the following list of technologies (some of which have been discussed in the prior two surveys), to be expanded upon in following subsections:
\begin{enumerate}
    \item FreeBSD Jails \cite{kamp2000jails}
    \item File Monitoring and Access Control (FMAC) \cite{prevelakis2001fmac}
    \item Vx32 \cite{ford2008vx32}
    \item Native Client \cite{yee2009native}
    \item Apiary \cite{potter2010apiary}
    \item MBOX \cite{kim2013mbox}
    \item System sandbox (for Microsoft Windows) \cite{vokorokos2015sandboxMSWIN}
\end{enumerate}

\subsection*{2.1 FreeBSD Jails}

The FreeBSD jail concept \cite{kamp2000jails} introduces a method of providing restricted computing environments through kernel-level partitioning of processes into ``jails.'' A process in ``jail'' sees a traditional FreeBSD environment with traditional resources (e.g. processes, file systems, networking), but restricts the privileged, root-level operations the process can perform (e.g. sending signals to processes outside of the jail). This functionality is implemented through the \texttt{jail} syscalls, requiring modifications to the FreeBSD kernel, and takes advantage of the functionality of \texttt{chroot}, with modifications, to protect the filesystem.

\subsection*{2.2 File Monitoring and Access Control (FMAC)}

Prevelakis and Spinellis \cite{prevelakis2001fmac} present a filesystem sandboxing solution by isolating a process' access to the filesystem through a File Monitoring and Access Control (FMAC) tool, which presents a mirror of the local filesystem. The sandbox mounts the tool as a filesystem and uses \texttt{chroot} to restrict a process to only view the isolated file system. Access control policies can be set up to allow the application to perform certain read or write operations on select files in the mirrored filesystem, effectively protecting the local filesystem from unauthorized access and modification.

\subsection*{2.3 Vx32}

Ford and Cox \cite{ford2008vx32} present a virtual machine for the 32-bit x86 instruction set, Vx32, as a library on which to build sandboxed applications. The virtual machine utilizes the x86 processor's segmentation hardware to sandbox guest data and employs dynamic translation to rewrite privileged instructions and sandbox guest code. Vx32 runs completely in user-mode and requires no modifications to the host kernel, although it has hardware, host kernel, and guest code requirements.

\subsection*{2.4 Native Client}

Google's Native Client \cite{yee2009native} is a sandbox for untrusted x86 code, specifically targeted at binary code to be executed in-browser. Native Client targets browser-based applications with computation that require native performance and is built from two layers of sandboxes: The inner sandbox performs binary analysis to ensure code is free from unsafe machine instructions and uses x86 segmented memory to restrict data access, while the outer sandbox performs kernel interposition to restrict access to syscalls.

\subsection*{2.5 Apiary}

Potter and Nieh \cite{potter2010apiary} present an innovative approach to application compartimentalization through the use of containers. Apiary's application isolation and fault containment advances build upon existing operating system isolation features (e.g. Solaris zones and FreeBSD jails), but enables a holistic display system across all containers and inter-application communication and integration through restrictive, shared filesystems. Apiary also introduces the Virtual Layered File System, an efficient way of combining multiple layers of file systems that a container can view, but also require strict access control policies. Apiary's benchmarks show that the container technique presented adds minimal overhead to the normal operation of containerized applications.

\subsection*{2.6 MBOX}

Kim and Zeldovich \cite{kim2013mbox} describe and implement a lightweight sandboxing mechanism, MBOX, to restrict an application's syscalls and filesystem accesses. MBOX achieves this through using \texttt{seccomp-bpf} as a kernel interposition resource, and utilizing a layered filesystem technique to restrict access to the local filesystem. Unlike Apiary, MBOX uses its layered filesystem to allow sandboxed applications to access local files and propose modifications, but stores the changes in a sandboxed area of persistent storage. Once the sandboxed application terminates, a user is given the option of committing any changes back into the local filesystem.

\subsection*{2.7 System sandbox (for Microsoft Windows)}

Vokorokos et al. \cite{vokorokos2015sandboxMSWIN} take a different approach to sandboxes by focusing solely on the Microsoft Windows platform. They assert that the most important operating system components of Windows that require protection are \textit{files}, \textit{system registry}, \textit{network interfaces}, and \textit{system resources}. The proposed sandboxing system protects these components through using various copy-on-write filters for the filesystem and system registry, blocking network access through the Windows firewall, and limiting access to system resources through Windows Job objects. Although the proposed solution solely targets Windows, the methods employed are largely analogous to methods often seen in Unix-based systems.

\section*{3. Research Methodology}
We plan to evaluate a sample of widely-used process isolation and restricted computing environments ranging from lightweight \texttt{chroot}- and \texttt{seccomp}-based jails to full-blown virtual machines. The hard (quantitative and objective) metrics in our evaluation are: \textit{startup time}, \textit{execution speed}, \textit{syscall speed}, and \textit{memory overhead}. The soft (subjective) metrics are: \textit{hardware requirements}, \textit{software/operating systems requirements}, \textit{ease of setup and launch}, \textit{granularity of configuration}, and \textit{configuration management}. We expect that the soft metrics will provide some context for the quantitative differences between the isolation techniques and reveal tradeoffs between functionality and performance.

Based on our literature review, we found these technologies and tools to be a representative sample of current methods of creating restricted computing environments:\vspace{0.5em}
{\small
\begin{itemize}
\item minijail and firejail
\item QEMU
\item Native Client
\item MBox
\item Linux Containers
\item FreeBSD jail
\item Docker
\item VirtualBox running Debian guest
\end{itemize}
}
To collect hard metrics, we will run benchmarks that stress CPU and memory resources. We will then analyze the results and examine the implementations of each tool to explain measurement trends. This may be repeated in an iterative process, for example running the same benchmark on increasingly stricter security configurations for each restricted environment. As part of the measurement process, we will note our experiences using these technologies to qualify our soft metrics.
\subsubsection*{3.1 Required Hardware}
Our tests will be performed on x86-64 Linux machines (which will require access to the CLIC lab, and maybe CRF accounts). We will use the same operating system distribution when possible. In the case of FreeBSD jail running on FreeBSD or minijail running on Chrome OS, for example, we will account for operating system differences in our analysis.
\subsubsection*{3.2 Required Software}
We seek to use the industry-standard SPEC CPU2017 benchmark \cite{limaye2018spec} as a test suite to gather performance metrics. However, we are not sure if it is practical, given its cost (\$1,000). Other possibilities include using open-source benchmarks such as PXZ and sysbench. These were used in a 2014 performance study on containers and virtual machines by IBM Research ~\cite{felter2014docker}. For measuring startup time and syscall time, we will use the \emph{perf} tool.
\section*{4. Hypothesis}
We hypothesize that there will be an inverse relationship between configurability and how ``lightweight'' a restricted computing tool is; that is, we expect that the more configurable or flexible the tool is to use (e.g. how granular of access controls can be set up), the longer it will take to start up and the larger memory footprint it will require. In particular, we anticipate Docker, VirtualBox VM, and QEMU to have significant startup overheads due to creation of a writable container layer for containers, and virtual disk creation for virtual machines.\\

For sandboxes relying on syscall filtering methods like \texttt{seccomp}, we hypothesize the main slowdown to be syscall speed due to interposition on a non-trivial fraction of those syscalls ~\cite{kim2013mbox}. It will be difficult for sandboxes to outperform containers and virtual machines with respect to execution time and memory overhead, as the latter's performance has shown to be close to native execution ~\cite{felter2014docker}. Furthermore, \texttt{seccomp-bpf} sandboxes may also have slower and manual set up time as programs need to be individually profiled with strace for effective syscall policy creation.

Finally, we believe that the quantitative and qualitative results found through this research can assist in determining the best kind of restricted computing environment technology for different classes of use cases. We aim to describe some of these classes and our recommendations for the technology to choose.
\section*{5. Projected Research Schedule}
\textbf{2/12-2/18} further literature review to acquire a detailed understanding of the underlying technologies used by each tool\\
\textbf{2/19-2/25} acquire and set up the software we intend to test\\
\textbf{2/26-3/4} acquire and set up benchmarking tools\\
\textbf{3/5-3/11} perform initial benchmarking on the listed technologies; create slides for project status report\\
\textbf{3/12-3/18} continue data collection; begin data analysis and comparisons\\
\textbf{3/19-3/25} finalize data collection and analysis; begin draft of abstract\\
\textbf{3/26-4/1} continue writing abstract; begin draft of each technology's implementation and the literature behind them\\
\textbf{4/2-4/8} expand on abstract into the extended abstract\\
\textbf{4/9-4/15} continue writing extended abstract\\
\textbf{4/16-4/22} begin work on project presentation slides\\
\textbf{4/23-4/29} continue presentation slides; continue expanding on extended abstract into final report\\
\textbf{4/30-5/6} finish final report




\bibliographystyle{abbrv}
\bibliography{proposal}
\end{document}


