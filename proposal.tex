\documentclass{proc}
\usepackage{url}
\linespread{1.2}

\begin{document}

\title{Project Proposal: A Container-Based Approach to Fault-Tolerant Host Monitoring on Commodity Operating Systems}

\author{Brett Jia \hspace{1em} Jennifer Bi}

\maketitle

\section*{Abstract}

In modern computer systems, users and developers often desire to monitor their operating systems for usage metrics, such as file system usage, CPU utilization, RAM, and others. Monitoring can be done through automated software that report metrics to a metrics aggregator, or through a user manually running certain tools that probe the operating system for data. In either case, the system could be at risk of damage and compromise from buggy or malicious software and user negligence or error. To address this problem, we present an approach to running host monitoring tools in containers with a read-only view of the surrounding system, guaranteeing fault tolerance and protection to the host operating system.

\section*{1. Introduction}

Despite the best efforts of software designers and system administrators, a major weakness of system administration and system monitoring is the reliance on bug-free software and perfect user execution. Some system monitoring tools such as \texttt{ps} rely on unprivileged reading virtual file system objects exposed by the operating system kernel, while other tools such as \texttt{lsof} require superuser privileges to display full metrics on a system's open file descriptors. Especially for the case of tools requiring superuser privileges, any system administration or system monitoring task could potentially be destructive to the host system through malicious software or user error if incorrect commands and arguments are executed, resulting in the expenditure of hours and money to restore the system and its contents to a state prior to disaster.

An early solution to the problem of fault tolerance is to utilize virtual machines to guarantee isolation between processes \cite{garfinkel2003terra}. However, while virtual machines can indeed be used to provide an isolated environment for untrusted code execution \cite{wen2012virtualization}, recent performance comparisons between hypervisor-based virtualization and container-based (i.e. lightweight or kernel-based) virtualization show that virtual machines exhibit more overhead with certain workloads when compared to kernel-supported container mechanisms \cite{felter2014docker, morabito2015hypervisors}.

Instead of hardware virtualization by way of virtual machines, recent work has emphasized creating fault tolerance with operating system virtualization \cite{soltesz2007container}. An early approach to operating system virtualization introduces a kernel interposition method to restrict an application's access to certain system calls, as implemented in Janus \cite{goldberg1996janus} and later in MBOX \cite{kim2013mbox}. Other sandboxing mechanisms have been introduced, including new system calls to create kernel-supported process isolation called jails \cite{kamp2000jails}, new file system tools leveraging \texttt{mount} and \texttt{chroot} to restrict file system access \cite{prevelakis2001fmac}, namespace isolation to create kernel-supported process containers \cite{biederman2006namespaces, menage2007containers}, and control groups to limit resource consumption of a group of processes \cite{menagecgroups}.

Modern containers combine these operating system virtualization approaches to create lightweight isolated execution contexts. The industry standard choice for Linux container technology is Docker, which combines Linux \textit{cgroups}, \textit{namespaces}, \textit{capabilities}, and more using its custom container runtime, \textit{libcontainer} \cite{hykes2014libcontainer}. With the formation of the Open Container Initiative (OCI) in 2015 \cite{opencontainerinitiative}, the design and construction of container platforms became standardized with OCI's \textit{runtime-spec} and \textit{image-spec}, providing a framework for distributors to develop their own cross-compatible container implementations.

In our research, we intend to explore the application of modern Linux container technologies to the area of system monitoring. In particular, we intend to address the problems of host stability and fault tolerance that arise from executing buggy or compromised system tools and from user negligence and error when performing system administration tasks. In the following sections, we list existing container and sandboxing technologies, our research approach, and our research timeline.

\section*{2. Literature Review}

In preparation for our research, we sought out existing literature on existing application isolation techniques. We discovered a diverse set of techniques used to create isolated and restricted environments for running untrusted code. Our findings are listed below in this section.

A prior survey of isolation systems and techniques from 2009 \cite{viswanathan2009isolation} categorizes isolation techniques into the following categories:
\begin{enumerate}
    \item Language-based isolation (e.g. type safety and compiler verification)
    \item Sandbox-based isolation (e.g. interposition between an application and the operating system's syscalls)
    \item Virtual machine-based isolation (e.g. Type I and Type II hypervisors)
    \item Kernel-based isolation (e.g. isolation between processes)
    \item Hardware-based isolation (e.g. hardware support for virtual memory addresses)
    \item Physical isolation (e.g. airgapped machines)
\end{enumerate}
The taxonomy of isolation techniques and a list of surveyed systems presented in the aforementioned paper provide a useful categorization of restricted computing environment techniques and useful comparisons of the taxonomic categories listed above. For the purposes of our research, we are mainly interested in sandbox-based and virtual machine-based isolation.

Another survey of virtualization technologies for untrusted code execution from 2012 \cite{wen2012virtualization} notes that untrusted code is usually executed in one of four categories:
\begin{enumerate}
    \item Application-level sandboxing through programming language features, kernel interposition, or resource access control policies
    \item Simulating an operating system environment through virtualizing an operating system's runtime API
    \item Containerizing an execution environment through kernel-supported isolation of all resources required by a process
    \item Virtualizing hardware and isolating full operating systems through Type I and Type II virtual machine monitors
\end{enumerate}
This survey by Wen et al. presents various examples of each type of restricted computing environment and discusses their strengths and weaknesses, however fails to present quantitative metrics to compare the technologies listed. Indeed, the research presented by Viswanathan and Neuman \cite{viswanathan2009isolation} also fails to present any sort of benchmarking for the surveyed technologies.

Although these two surveys are useful in providing categorization and terminology, we find them to be dated, as newer forms of restricted computing environments have been developed in recent years. Our own literature review presents the following list of technologies (some of which have been discussed in the prior two surveys), to be expanded upon in following subsections:
\begin{enumerate}
    \item FreeBSD Jails \cite{kamp2000jails}
    \item File Monitoring and Access Control (FMAC) \cite{prevelakis2001fmac}
    \item Vx32 \cite{ford2008vx32}
    \item Native Client \cite{yee2009native}
    \item Apiary \cite{potter2010apiary}
    \item MBOX \cite{kim2013mbox}
    \item System sandbox (for Microsoft Windows) \cite{vokorokos2015sandboxMSWIN}
\end{enumerate}

\subsection*{2.1 FreeBSD Jails}

The FreeBSD jail concept \cite{kamp2000jails} introduces a method of providing restricted computing environments through kernel-level partitioning of processes into ``jails.'' A process in ``jail'' sees a traditional FreeBSD environment with traditional resources (e.g. processes, file systems, networking), but restricts the privileged, root-level operations the process can perform (e.g. sending signals to processes outside of the jail). This functionality is implemented through the \texttt{jail} syscalls, requiring modifications to the FreeBSD kernel, and takes advantage of the functionality of \texttt{chroot}, with modifications, to protect the filesystem.

\subsection*{2.2 File Monitoring and Access Control (FMAC)}

Prevelakis and Spinellis \cite{prevelakis2001fmac} present a filesystem sandboxing solution by isolating a process' access to the filesystem through a File Monitoring and Access Control (FMAC) tool, which presents a mirror of the local filesystem. The sandbox mounts the tool as a filesystem and uses \texttt{chroot} to restrict a process to only view the isolated file system. Access control policies can be set up to allow the application to perform certain read or write operations on select files in the mirrored filesystem, effectively protecting the local filesystem from unauthorized access and modification.

\subsection*{2.3 Vx32}

Ford and Cox \cite{ford2008vx32} present a virtual machine for the 32-bit x86 instruction set, Vx32, as a library on which to build sandboxed applications. The virtual machine utilizes the x86 processor's segmentation hardware to sandbox guest data and employs dynamic translation to rewrite privileged instructions and sandbox guest code. Vx32 runs completely in user-mode and requires no modifications to the host kernel, although it has hardware, host kernel, and guest code requirements.

\subsection*{2.4 Native Client}

Google's Native Client \cite{yee2009native} is a sandbox for untrusted x86 code, specifically targeted at binary code to be executed in-browser. Native Client targets browser-based applications with computation that require native performance and is built from two layers of sandboxes: The inner sandbox performs binary analysis to ensure code is free from unsafe machine instructions and uses x86 segmented memory to restrict data access, while the outer sandbox performs kernel interposition to restrict access to syscalls.

\subsection*{2.5 Apiary}

Potter and Nieh \cite{potter2010apiary} present an innovative approach to application compartimentalization through the use of containers. Apiary's application isolation and fault containment advances build upon existing operating system isolation features (e.g. Solaris zones and FreeBSD jails), but enables a holistic display system across all containers and inter-application communication and integration through restrictive, shared filesystems. Apiary also introduces the Virtual Layered File System, an efficient way of combining multiple layers of file systems that a container can view, but also require strict access control policies. Apiary's benchmarks show that the container technique presented adds minimal overhead to the normal operation of containerized applications.

\subsection*{2.6 MBOX}

Kim and Zeldovich \cite{kim2013mbox} describe and implement a lightweight sandboxing mechanism, MBOX, to restrict an application's syscalls and filesystem accesses. MBOX achieves this through using \texttt{seccomp-bpf} as a kernel interposition resource, and utilizing a layered filesystem technique to restrict access to the local filesystem. Unlike Apiary, MBOX uses its layered filesystem to allow sandboxed applications to access local files and propose modifications, but stores the changes in a sandboxed area of persistent storage. Once the sandboxed application terminates, a user is given the option of committing any changes back into the local filesystem.

\subsection*{2.7 System sandbox (for Microsoft Windows)}

Vokorokos et al. \cite{vokorokos2015sandboxMSWIN} take a different approach to sandboxes by focusing solely on the Microsoft Windows platform. They assert that the most important operating system components of Windows that require protection are \textit{files}, \textit{system registry}, \textit{network interfaces}, and \textit{system resources}. The proposed sandboxing system protects these components through using various copy-on-write filters for the filesystem and system registry, blocking network access through the Windows firewall, and limiting access to system resources through Windows Job objects. Although the proposed solution solely targets Windows, the methods employed are largely analogous to methods often seen in Unix-based systems.

\section*{3. Research Methodology}
We plan to implement an isolation mechanism for read-only host monitoring. First, we will define the set of resources which will be readable by applications running inside the container. For example, a reasonable monitoring tool would access information about CPU load, memory usage, disk usage, process information, which we want to make available. On the other hand, we may want to restrict access to other resources such as named pipes or network sockets.

Our container will relax the isolation provided by containers like Docker, but will be otherwise similar. It makes sense then to extend runC to implement our read-only isolation, rather than building our own container. Currently, runC uses \texttt{seccomp-bpf} filters to interpose on syscalls, but their rule-based filtering does not allow for more advanced logic. Our work will be to add additional syscall handling.

Finally we will evaluate our container on a range of host-monitoring and application performance monitoring tools. Our tentative list includes: linux commands like \texttt{top} or \texttt{free}, more complex utilities like \texttt{sysstat}, remote monitoring tools like \emph{GKrellM}, and graphical tools like \emph{Cacti}, \emph{Nagios}. We will also ensure standard unix tools work (\texttt{awk, grep, vim, md5sum}). The main soft evaluation metric is ease of use compared to monitoring directly on the most and monitoring with a Docker container. The hard metrics include speed of instantiation, syscall speed, scalability with respect to memory and cpu usage (i.e., running multiple containers on the same host).

In addition to well-behaving tools, we will run malicious programs to show that our container protects host resources from malicious behavior.

\subsubsection*{3.1 Required Hardware}
We will develop in VMs, but test and measure performance on x86-64 Linux machines (which will require access to the CLIC lab, and maybe CRF accounts).

\subsubsection*{3.2 Required Software}
Our required software is mostly open-source or free: standard system tools that ship with Linux, \emph{Cacti, Nagios, GKrellM, sysstat, Docker}.

\section*{4. Hypothesis}



\section*{5. Projected Research Schedule}
\textbf{3/5-3/11} perform initial tests on runC, explore runC codebase; create slides for project status report\\
\textbf{3/12-3/18} continue data collection; begin data analysis and comparisons\\
\textbf{3/19-3/25} finalize data collection and analysis; begin draft of abstract\\
\textbf{3/26-4/1} continue writing abstract; begin draft of each technology's implementation and the literature behind them\\
\textbf{4/2-4/8} expand on abstract into the extended abstract\\
\textbf{4/9-4/15} continue writing extended abstract\\
\textbf{4/16-4/22} begin work on project presentation slides\\
\textbf{4/23-4/29} continue presentation slides; continue expanding on extended abstract into final report\\
\textbf{4/30-5/6} finish final report




\bibliographystyle{abbrv}
\bibliography{proposal}
\end{document}


